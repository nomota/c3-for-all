# Memmory Allocation

There are mutiple memory allocators available in C3.

All allocators conform `interface Allocator {}` requirement, so they are inter-changeable each other in some way.

* Note: Standard libraries in `std::core` are imported implicitly by the compiler. Memory allocators are defined in standard library `std::core::mem::allocator`, and you don't have to import in your code.

### Stack vs heap allocation

The problem with stack allocations is that the length and sizes must be known up front. Imagine if we wanted to create an array with `n` number of entries and return that as a slice.

A first attempt might be:

```c3
const MAX_NUMBER = 100;
<* @require n >= 0 && n <= MAX_NUMBER *>
fn int[] create_array(int n)
{
    int[MAX_NUMBER] arr;
    for (int i = 0; i < n; i++)
    {
        arr[i] = i;
    }
    return arr[:n];  // Error: returns a pointer to a stack allocated variable
}
```

Aside from the problem with having a `MAX_NUMBER`, we can't return a pointer to this array, even as a slice, because the memory where `arr` is stored is returned when the call to `create_array` returns.

The normal solution here is to allocate memory on the heap instead, the code might look like this:

```c3
<* @require n >= 0 *>
fn int[] create_array(int n)
{
    int* arr = malloc(n * int.sizeof);
    for (int i = 0; i < n; i++)
    {
        arr[i] = i;
    }
    return arr[:n]; // Turn the pointer into a slice with length "n"
}
```

This allocates enough memory to hold `n` ints, and returns the result.

The downside is that we must make sure that we release the memory back when we're done:

```c3
fn void test()
{   
    int[] array = create_array(3);
    do_things(array);
    free(array); // Release memory back to the OS
}
```

* Note: There are convenience functions in the standard library to allocate arrays on the heap. Use `Type[] mem::new_array(Type, num)` - zero initialized - or `Type[] mem::alloc_array(Type, num)` - not initialized - rather than `malloc` directly.  
:

### Default (heap) allocator

The default (heap) allocator is mapped to `libc`'s memory allocation. These functions/macros are available, just like in C.

```c3
void* malloc(usz size); // uninitialized
void* calloc(usz size); // fills zero
void* realloc(void* ptr, usz new_size);
void free(void* ptr);
```

To achieve better type awareness, a new set of allocations are also available.

```c3
Type* p = mem::alloc(Type); // uninitialized
Type* p = mem::new(Type[, {initial value}]); // zero filled if no initial value
Type[] p = mem::alloc_array(Type, usz number); // uninitalized
Type[] p = mem::new_array(Type, usz number); // zero-filled
Type* p = @clone(Type value);
Type[] p = @clone_slice(Type[] slice);
```

Following is a traditional way of allocating memories just like in C.

```c3
const int N = 10;

fn void test() 
{
    char* p = malloc(N); // N bytes
    p = realloc(p, N * 2);
    char[] q = ((char*)malloc(char.sizeof * N))[..N-1];

    int* r = malloc(int.sizeof * N); // N ints
    int[] s = ((int*)malloc(int.sizeof * N))[..N-1];

    free(p); free(q);
    free(r); free(s);
}
```


* Note: `malloc()` returns `void*`, which is easily casted to `char*` or `int*`. In order to get `char[]` slice or `int[]` slice, you need to cast the `void*` to corresponding pointer and then do slicing `[..N-1]` over the pointer.

* Note: `free()` is applied to any kind of pointer or slice.

* Note: there's no error handling. That's because `malloc()` does not return error optional, but panics on error. Normally memory error is critical and there's little to do in that situation, but to panic. To catch the memory error, there are special macros with `_try()` suffix.

Following is more C3 way of allocation.

```c3
fn void test() 
{
    const int N = 10;

    int* p = mem::alloc(int); // one int, uninitialized
    int* q = mem::new(int, 7); // initialized
    int[] r = mem::new_array(int, N); // N ints, zero filled
    int* s = @clone(7);

    free(p); free(q);
    free(r); free(s);
}
```

```c3
struct MyT {
    String name;
    int birth_year;
}

const int N = 10;

fn void test()
{
    MyT* p = mem::alloc(MyT); // uninitialized
    MyT* q = mem::new(MyT, {"Charlie", 7}); // initialized
    MyT[] r = mem::alloc_array(MyT, N); // N MyT's, uninitialized
    MyT* s = @clone(*q);

    free(p); free(q);
    free(r); free(s);
}
```

### defer free() within scope

In a scope { ... }, you can register `defer` statements that are to be invoked right before the exit of the scope.

Deferring `free()` right after allocation is a good habit to prevent memory leaks.

There are three kinds of defers, depending on how the scope exits:
* exits normally
* exits returning an error
* exits returning a normal value.

```c3
defer { ... } // on any kind of exit
defer (catch err) { io::printfn("%s", err); }  // on error returning exit
defer try { io::printfn("ok return"); } // on value returning exit
```

A typical defer usage is like this. Put `defer free()` right after allocation.

```c3
fn void test()
{
    char* p = malloc(50);
    defer free(p);

    // do the rest
} // free(p) gets invoked here
```

If you want `free()` to get invoked only when error occurs, use `defer (catch err) { free() }`.

```c3
import std::io;

fn bool file_not_found() { return true; }
fn void fill_in_data(char[] p) { p[0] = 'A'; }

fn char[]? test()
{
    char[] data = mem::new_array(char, 12);

    defer (catch err) {
        io::printfn("Error found: %s", err);
        free(data);
    }

    if (file_not_found()) {
        // deferred (catch err) gets invoked here 
        return io::FILE_NOT_FOUND?;
    }

    fill_in_data(data);

    return data;
}
```

### Temp allocator

Temporary allocator is designed to handle temporary memory allocation. It is more an easy-to-use allocator where you usually don't want to think about memory management and is used a lot inside the standard library.

To use temporary allocator, there are dedicated macros as follows, all with 't' prefixed.

```c3
void* p = tmalloc(usz size);
void* p = tcalloc(usz size); // fills zero
void* p = trealloc(void* ptr, usz new_size);
Type* p = mem::talloc(Type); // uninitialized
Type* p = mem::tnew(Type[, {initial value}]); // zero filled if no initial value
Type[] p = mem::temp_array(Type, usz number);
Type[] p = mem::talloc_array(Type, usz number);
Type* p = @tclone(Type value);
Type[] p = @tclone_slice(Type[] slice);
```

Temporary memory does not get freed by itself. We need to confine them within certain scope, using special macros which do the necessary cleanups.

### @pool() macro scope

The `@pool()` macro is a way to do  manual memory management more easily, with the help of temporary allocator. It's a macro, but practically and visually it acts like a special kind of scope.

The `@pool()` macro scope, on exit, automatically cleans up all temporary allocations within the scope.

The `@pool()` macro scope is written like this.

```c3
fn void inner_function()
{
    char* buf2 = mem::talloc(char); // temp alloc
    char* buf3 = mem::tnew(char); // temp new
    char[] buf4 = mem::temp_array(char,10); // temp array
}

fn void test() 
{
    char* bufx;
    // do something
 
    @pool() {
        char* buf1 = mem::tmalloc(10); // temp malloc
        bufx = malloc(100); // non-temporary

        inner_function();
    }; // buf1, buf2, buf3, buf4 get freed here
    // don't miss semicolon

    // do something

    free(bufx); // non-temporary memory needs explicit free()
}
```

* Note: Unlike `defer free()`'d memory which is confined within a single scope, temporary memory can go beyond a scope `{ ... }`, but it needs to be placed within `@pool()` macro scope, in order to get properly cleaned up.

`@pool()` macro scope can be nested.

```c3
fn void test()
{
    @pool() {
        char* p = mem::talloc(char);

        @pool() {
            char* q = mem::tnew(char);
        }; // q gets freed here
    }; // p gets freed here
    // don't miss semicolon
}
```

A function may get `@pool()` macro scoped by using `=>` single-line function body syntax like this.

```c3
fn void test() => @pool()
{
    char* p = tmalloc(500);
} // p gets freed here
```

* Note: temporary memory should not be transferred to other thread or outside scope of `@pool()` macro.

Without any explicit `@pool()` macro, temporary memories still get freed at the end of `main()`.

```c3
fn void test()
{
    char* p = mem::tnew(char, 'a');
} 

fn void main() // implicitly => @pool() here
{
    test();
} // p gets freed here
```

### @pool_init() macro

If you want to specify initial size of reserved memory for the temporary allocator, use `@pool_init(size)` macro. 

```c3
@pool_init(4096) // reserve 4096 bytes up-front
{
    // temporary allocations
}; // cleans up all temporary allocations
```  


### Functions that allocate

Standard library functions that allocate generally require you to pass an allocator as first argument.

Default (heap) allocator and temporary allocators are declared as `@builtin`, and you can use it anywhere needed.

* `mem`: default heap allocator
* `tmem`: temporary allocator

```c3
List{int} list;
list.init(mem); // "list" will use the heap allocator
list.push(1);
list.push(42);
io::printn(list); // Prints "{ 1, 42 }"
list.free(); // Free the memory in the list
```

If you are using `mem`, then in general you will need to free it in some way. Either it's built into the type, such as in the `List` example above, or else you will need to handle it yourself, like in this case:

```c3
String s = string::format(mem, "Hello %s", "World"); 
// The string "s" is allocated on the heap
io::printn(s); // Prints "Hello World"
s.free(); // Frees the string
```

On the other hand, if you use the temp allocator, you only need to make sure it's wrapped in a `@pool()` scope:

```c3
@pool()
{
   List{int} list;
   list.init(tmem); // "list" will use the temp allocator
   list.push(1);
   list.push(42);
   io::printn(list);
   
   String s = string::format(tmem, "Hello %s", "World"); 
   io::printn(s);
}; // s and list are freed here, because they used temp memory
```

Because of the usefulness of the temp allocator idiom, there are often temp allocator versions of functions, prefixed "t" or "temp_":

```c3
@pool()
{
   List{int} list;
   list.tinit(); // Use the temp allocator
   list.push(1);
   list.push(42);
   
   String s = string::tformat("Hello %s", "World"); // Use the temp allocator
};
```

### Implicit initialization

Some types, such as `List`, `HashMap` and `DString` will use the temp allocator by default if they are not initialized. 

```c3
@pool()
{
   List{int} list; // declared, but not initialized
   list.push(1); // implicitly initialize with the temp allocator
   list.push(42);
   
   DString str; // DString is a dynamic string
   str.appendf("Hello %s", "World");
   // The "appendf" implicitly initializes "str" with the temp allocator
   str.insert_at(5, ",");            
   str.append("!");
   io::printn(str); // Prints Hello, World!
}; // list and str is freed here
```

This is often useful for locals, but in the case of globals, you might want the container to default use the heap allocator. 

For most containers there is a `ONHEAP` constant which
allows you to statically initialize globals to use the heap allocator:

```c3
List {int} l = list::ONHEAP {int};

fn void test()
{
    l.push(1); // implicitly initialize using heap allocator, not the temp allcator.
}

fn void main()
{
    test();

    l.free();
}
```

### Using other allocators

For default allocator `mem` and temp allocator `tmem`, there are abbriviated macros without having to specify `mem` or `tmem` everytime.

For other kind of allocators, following allocation macros are available, where `allocx` is an allocator (interface).

```c3
Allocator allocx; // interface, not a struct
void* p = allocator::malloc(allocx, usz size);
void* p = allocator::calloc(allocx, usz size); // zero-filled
void* p = allocator::realloc(allocx, void* ptr, usz new_size);
Type* p = allocator::alloc(allocx, Type); // uninitialized
Type* p = allocator::new(allocx, Type[, {initial value}]); // zero filled if no initial value
Type[] p = allocator::new_array(allocx, Type, usz number);
Type[] p = allocator::alloc_array(allocx, Type, usz number);
Type* p = allocator::@clone(allocx, Type value);
Type[] p = allocator::@clone_slice(allocx, Type[] slice);

```

To get `allocx` here, you need to initialize specific allocator properly

```c3
// properly initialize OnStack allocator
char[1000] buffer;
OnStackAllocator osa;
osa.init(&buffer, mem);
defer osa.free();

Allocator allocx = &osa; // common interface
```

It is somewhat verbose to use this kind of calls directly in everyday coding. For practical use, there are some easier ways to use specific allocators selectively.

### mem::@scoped(allocx) macro scope

Default allocator can be easilly replaced by other kind of allocators by using `mem::@scope(allocx)` macro scoping. In that scope, the default allocator `mem` gets temporarily replaced by given `allocx` allocator.

In that scope, all allocation functions uses `allocx` instead of `mem`. 

* Note: 't'-prefixed functions remain same, still using `tmem`.

Following three examples are exactly the same.

```c3
fn void test1()
{
    @pool() {
         mem::@scoped(tmem) // use tmem as default allocator in this scope
        {
            int* p = malloc(10);
        };
    };
}

fn void test2()
{
    @pool() {
        int* p = tmalloc(10); // 't'-prefixed functions use tmem
    };
}

fn void test3()
{
    @pool() {
        int* p = allocator::malloc(tmem, 10);
    };
}
```

If you're nesting macro scopes, be careful not to make subtle mistakes. If we change the nesting order of `test1()` above, code gets slightly different meaning.

```c3

fn void test11()
{
    @pool() {
         mem::@scoped(tmem) // use tmem as default allocator in this scope
        {
            int* p = malloc(10); // allocate with tmem
        };
        int* q = malloc(10); // allocate with mem 
    }; // p gets free'd here, q is a leak
}

fn void test12()
{
    mem:@scoped(tmem) { // use tmem as default allocator in this scope
        @pool() {
            int* p = malloc(10); // allocate with tmem
        }; // p gets free'd here
        int* q = malloc(10); // allocate with tmem
    }; // q is a leak unless no @pool() covers test12() from outside
}
```

### Tracking allocator

Tracking allocator is a powerful tool to spot memory leaks. Tracking allocator gets other allocator (like `mem`), and keeps track of every alloc/free by that allocator, and gives report afterwards. 

```c3
fn void test()
{
    char* p = mem::alloc(char); // memory leak here
}

fn void main()
{
    TrackingAllocator tra; // allocator struct
    tra.init(mem); // properly unitialize
    defer {
        tra.print_report();
        tra.free();
    }

    mem::@scoped(&tra) {
        test();
    };

    // do something else

} // tra.print_report() reports a leak
```

* Note: Tracking allocator indirectly calls other allocator, and manages its own book-keeping information, which causes subtle issue hard to detect.

Following is an example that leads to a wrong leakage report.
 
```c3
fn void test(Allocator allocx)
{
    @mem::scoped(allocx) {
        char* p = mem::alloc(100);
    };
}

fn void main()
{
    TrackingAllocator tra; // allocator struct
    tra.init(tmem); // use temporary allocator
    defer {
        tra.print_report();
        tra.free();
    }

    @pool() {
        test(&tra);
    }; // in fact, p gets freed here, but tra does not know that

} // tra reports wrong leakage report here
```

### Easier macro scopes

Two macros are ready to use without much of confusion. These two macros utilize Tracking allocator.

It's more recommended to use these macro scopes to prevent subtle mistakes with Tracking allocator.
 
```c3
mem::@report_heap_allocs_in_scope()
{
    // your code in doubt here
}; // produces report here

@assert_leak() {
    // your code in doubt here
}; // keeps silent if there's no leak
```

Stack memory is a lot faster than heap memory, and stack memories are free'd automatically. So it would be very effecient to allocate memories in stack. 

OnStack allocator is ready for that purpose. But again, direct handling of this allocator may cause subtle mistakes, and two handy macro scopes are ready to use.

```c3
fn void test1() 
{
    char* x;
    char* y;
    @stack_pool(1024) // use 1024 bytes of chunk in stack
    {
        x = malloc(1000); // allocated in stack
        y = malloc(1000); // allocated in heap using default allocator mem
    }; // all memories get freed here (stack popped)

    // free(x); // don't do double free
    // free(y); // don't do double free
}

fn void test2(Allocator allocx) 
{
    char* x;
    char* y;
    @stack_mem(1024; allocx) // use 1024 bytes of chunk in stack
    {
        x = malloc(1000); // allocated in stack
        y = malloc(1000); // allocated in heap using allocx allocator
    }; // all memories get freed here (stack popped)

    // free(x); // don't do double free
    // free(y); // don't do double free
}
```

The drawback of OnStack allocator is that it needs to reserve given size of chunk up-front in stack, regardless of actual allocations. This might waste of stack space if the size is too large, and may cause stack overflow and panic.

### _aligned(), _with_padding() allocations

If you're dealing with some over-aligned types, typically vectors with alignment greater than 16, then you need to use functions with '_aligned' suffix.

```c3
void* p = malloc_aligned(usz size, usz align);
void* p = calloc_aligned(usz size, usz align); // fills zero
void* p = realloc_aligned(void* ptr, usz new_size, usz align);
Type* p = mem::alloc_aligned(Type); // uninitialized
Type* p = mem::new_aligned(Type[, {initial value}]); // zero filled if no initial value
Type[] p = mem::new_array_aligned(Type, usz number);
Type[] p = mem::alloc_array_aligned(Type, usz number);
Type* p = @tclone_aligned(Type value);
Type[] p = @tclone_slice_aligned(Type[] slice);
void free_aligned(void* ptr);
```

* Note: Make sure that `_aligned` memory get freed only by `free_aligned()`


When you need to add additional memory at the end of the allocation, you can use `_with_padding` variations. Padding is mostly used with structs that have a flexible array member.


```c3
void* p = malloc_with_padding(usz size, usz padding);
void* p = calloc_with_padding(usz size, usz padding); // fills zero
void* p = realloc_with_padding(void* ptr, usz new_size, usz padding);
Type* p = mem::alloc_with_padding(Type, usz padding); // uninitialized
Type* p = mem::new_with_padding(Type, usz padding, {initial value});
```

### _try() allocations

Note that all above allocations return simple pointer or simple slice, meaning that they don't return error optional. If error occurs, they rather go panic, and do not allow catch errors.

If you want to catch memory errors, following macros are available. It's not recommended though, because underlying libc's malloc() itself is not stable on memory error situation, for example, due to memory over-commit in linux. Use these allocations only when you are absolutely sure about what you're doing.

```c3
Allocator allocx;
void*? p = allocator::malloc_try(allocx, usz size, usz align);
void*? p = allocator::calloc_try(allocx, usz size); // fills zero
void*? p = allocator::realloc_try(allocx, void* ptr, usz new_size);
Type*? p = allocator::alloc_try(allocx, Type); // uninitialized
Type*? p = allocator::new_try(allocx, Type[, {initial value}]); // zero filled if no initial value
Type[]? p = allocator::new_array_try(allocx, Type, usz number);
Type[]? p = allocator::alloc_array_try(allocx, Type, usz number);
Type*? p = allocator::@tclone_try(allocx, Type value);
Type[]? p = allocator::@tclone_slice_try(allocx, Type[] slice);
void? allocator::free_try(allocx,void *ptr);
```

The `_try()` macros are indeed not that useful when using `mem`, but they might be useful if you're using another allocator, like the standard Arena allocator which will return a fault (OOM) when it has no memory left in its arena.


### Which allocator to use

* Default (heap) allocator: it is used by default
* Temp allocator: if you want remove free() for temporary memories allocated in certain range, it's ready to use by default
* Libc Allocator: if you want to use libc's allocations directly
* Null allocator: if you make sure no allocation is made in certain scope like `mem:@scoped(null_allocx) { ... };`.
* Vmem allocator: if you want to use virtual memory
* Tracking allocator: if you want to track all alloc/free to detect leaks
* Arena allocator: reserve a chunk of memory up-front, use it piece after piece, and destroy them all at once
* BackedArena allocator: if you want to give some specific kind of memory to Arena allocator, the `BackedArenaAllocator` also falls back to its backing allocator AND supports mark and sweep, very cool feature.
* DynamicArena allocator: if you want to allow the reserved chunk to grow dynamically when needed, in an Arena allocator. DynamicArena allocator is essentially a linked list of Arena allocators.
* OnStack allocator: if you want to allocate on stack
* SimpleHeap allocator: This allocator is intended to be used in environments where there isn't any native libc malloc, and it has to be emulated from a memory region, or wrapping linear memory as is the case for plain WASM.

### Compiler/build options 

TO DO

There are compiler options that affect memory allocations.

There are build options in `project.json` that affect memory allocations.





